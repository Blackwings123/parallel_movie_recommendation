{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aw_XLGtNFPe3"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import time\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from functools import wraps\n",
        "from math import trunc\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from numba import jit, cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZV4MEKIrFPe7"
      },
      "outputs": [],
      "source": [
        "# VARIANTS object defines data configurations for different file sizes.\n",
        "# Each key represents the data size (e.g., \"100k\" for 100 thousand).\n",
        "VARIANTS = {\n",
        "    \"100k\": {\"filename\": \"u.data\", \"sep\": \"\\t\"},\n",
        "    \"1m\": {\"filename\": \"ratings.dat\", \"sep\": r\"::\"},\n",
        "    \"20m\": {\"filename\": \"ratings.csv\", \"sep\": \",\"},\n",
        "    \"32m\": {\"filename\": \"ratings.csv\", \"sep\": \",\"},\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gMcZPCBiFPe-"
      },
      "outputs": [],
      "source": [
        "# Define the chosen data variant (e.g., \"100k\", \"1m\", \"20m\" or \"32m\")\n",
        "variant = \"32m\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "axOeJLwcFPfA"
      },
      "outputs": [],
      "source": [
        "# Check if the chosen variant is a valid key in the VARIANTS object\n",
        "if variant not in VARIANTS:\n",
        "    # If not valid, raise an error\n",
        "    raise ValueError(\n",
        "        f\"Invalid variant: {variant}. Valid options are {list(VARIANTS.keys())}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TM1JFuOOFPfB"
      },
      "outputs": [],
      "source": [
        "# Construct the URL for downloading the data based on the chosen variant\n",
        "url = f\"http://files.grouplens.org/datasets/movielens/ml-{variant}.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "C6kseegJFPfC"
      },
      "outputs": [],
      "source": [
        "# Extract information from the VARIANTS object for the chosen variant\n",
        "variant_info = VARIANTS[variant]\n",
        "\n",
        "# Destructure filename property from the variant information\n",
        "filename = variant_info[\"filename\"]\n",
        "\n",
        "# Construct the directory name based on the variant\n",
        "dirname = f\"ml-{variant}\"\n",
        "\n",
        "# Construct the path to the downloaded zip file\n",
        "zip_path = os.path.join(dirname + \".zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZE3vDU6iFPfD"
      },
      "source": [
        "# ==================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "w5bkdw6xFPfH"
      },
      "outputs": [],
      "source": [
        "# Download the data from the URL and save it to the zip_path\n",
        "# with urllib.request.urlopen(url) as r, open(zip_path, \"wb\") as f:\n",
        "#     # Copy the downloaded data from the response to the file\n",
        "#     shutil.copyfileobj(r, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "l3G55iOVFPfL"
      },
      "outputs": [],
      "source": [
        "# Extract the data from the downloaded zip file\n",
        "# with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
        "#     # Extract all files from the zip archive to the current directory\n",
        "#     zf.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "I1URhWdTFPfN"
      },
      "outputs": [],
      "source": [
        "# Remove zip file after extraction (optional)\n",
        "# os.remove(zip_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "HIYBHKaMFPfP"
      },
      "outputs": [],
      "source": [
        "# Construct the path to the CSV file\n",
        "csv_path = os.path.join(dirname, filename)\n",
        "\n",
        "# Define the column names for the data\n",
        "names = [\"u_id\", \"i_id\", \"rating\", \"timestamp\"]\n",
        "\n",
        "# Define data type for each column\n",
        "dtype = {\"u_id\": np.uint32, \"i_id\": np.uint32, \"rating\": np.float64}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "KLWY47xvFPfP"
      },
      "outputs": [],
      "source": [
        "# Read the CSV data into a Pandas DataFrame\n",
        "df = pd.read_csv(\n",
        "    csv_path,\n",
        "    names=names,\n",
        "    dtype=dtype,\n",
        "    header=0,\n",
        "    sep=VARIANTS[variant][\"sep\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fDP3RxAXFPfP"
      },
      "outputs": [],
      "source": [
        "# Drop the \"timestamp\" column from the DataFrame\n",
        "df.drop(\"timestamp\", inplace=True, axis=1)\n",
        "\n",
        "# Sort the DataFrame by the \"u_id\" column (assuming user IDs)\n",
        "df.sort_values(by=\"u_id\", inplace=True)\n",
        "\n",
        "# Reset the index after sorting (optional, keeps row numbers aligned with data)\n",
        "df.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "EH7u1fYxFPfQ"
      },
      "outputs": [],
      "source": [
        "# Randomly sample 80% for training set\n",
        "train = df.sample(frac=0.8, random_state=7)\n",
        "\n",
        "# Sample 50% from remaining for validation\n",
        "val = df.drop(train.index.tolist()).sample(frac=0.5, random_state=8)\n",
        "\n",
        "# Remaining data becomes test set\n",
        "test = df.drop(train.index.tolist()).drop(val.index.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0qX8AY8GFPfR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\DUY\\AppData\\Local\\Temp\\ipykernel_2156\\3120321745.py:1: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
            "  @jit(cache=True)\n"
          ]
        }
      ],
      "source": [
        "@jit(cache=True)\n",
        "def shuffle(X):\n",
        "    np.random.shuffle(X)\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wDUB3USXFPfS"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\DUY\\AppData\\Local\\Temp\\ipykernel_2156\\660544247.py:1: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
            "  @jit(cache=True)\n"
          ]
        }
      ],
      "source": [
        "@jit(cache=True)\n",
        "def initialization(n_users, n_items, n_factors):\n",
        "    # Initialize user biases with zeros (n_users length)\n",
        "    bu = np.zeros(n_users)\n",
        "\n",
        "    # Initialize item biases with zeros (n_items length)\n",
        "    bi = np.zeros(n_items)\n",
        "\n",
        "    # Random user factors (normal distribution, mean 0, std 0.1)\n",
        "    pu = np.random.normal(0, 0.1, (n_users, n_factors))\n",
        "\n",
        "    # Random item factors (normal distribution, mean 0, std 0.1)\n",
        "    qi = np.random.normal(0, 0.1, (n_items, n_factors))\n",
        "\n",
        "    return bu, bi, pu, qi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "hofqo84m87Tc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\DUY\\AppData\\Local\\Temp\\ipykernel_2156\\533422370.py:1: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
            "  @jit(cache=True)\n"
          ]
        }
      ],
      "source": [
        "@jit(cache=True)\n",
        "def run_epoch_cpu(X, bu, bi, pu, qi, global_mean, n_factors, lr, reg):\n",
        "    # Loop through each rating in the data matrix X\n",
        "    for i in range(X.shape[0]):\n",
        "        # Extract user ID, item ID, and rating from current row\n",
        "        user, item, rating = int(X[i, 0]), int(X[i, 1]), X[i, 2]\n",
        "\n",
        "        # Predict current rating\n",
        "        pred = global_mean + bu[user] + bi[item]\n",
        "        for factor in range(n_factors):\n",
        "            pred += pu[user, factor] * qi[item, factor]\n",
        "\n",
        "        # Calculate the error between predicted and actual rating\n",
        "        err = rating - pred\n",
        "\n",
        "        # Update user and item biases with learning rate (lr) and regularization (reg)\n",
        "        bu[user] += lr * (err - reg * bu[user])\n",
        "        bi[item] += lr * (err - reg * bi[item])\n",
        "\n",
        "        # Update user and item latent factors for all factors (n_factors)\n",
        "        for factor in range(n_factors):\n",
        "            puf = pu[user, factor]\n",
        "            qif = qi[item, factor]\n",
        "\n",
        "            pu[user, factor] += lr * (err * qif - reg * puf)\n",
        "            qi[item, factor] += lr * (err * puf - reg * qif)\n",
        "\n",
        "    return bu, bi, pu, qi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7fStP-PWFPfS"
      },
      "outputs": [],
      "source": [
        "@cuda.jit\n",
        "def run_epoch_gpu(X, bu, bi, pu, qi, global_mean, n_factors, lr, reg):\n",
        "    c = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
        "\n",
        "    # Loop through each rating in the data matrix X\n",
        "    if c < X.shape[0]:\n",
        "        # Extract user ID, item ID, and rating from current row\n",
        "        user, item, rating = int(X[c, 0]), int(X[c, 1]), X[c, 2]\n",
        "\n",
        "        # Predict current rating\n",
        "        pred = global_mean + bu[user] + bi[item]\n",
        "        for factor in range(n_factors):\n",
        "            pred += pu[user, factor] * qi[item, factor]\n",
        "\n",
        "        # Calculate the error between predicted and actual rating\n",
        "        err = rating - pred\n",
        "\n",
        "        # Update user and item biases with learning rate (lr) and regularization (reg)\n",
        "        bu[user] += lr * (err - reg * bu[user])\n",
        "        bi[item] += lr * (err - reg * bi[item])\n",
        "\n",
        "        # Update user and item latent factors for all factors (n_factors)\n",
        "        for factor in range(n_factors):\n",
        "            puf = pu[user, factor]\n",
        "            qif = qi[item, factor]\n",
        "\n",
        "            pu[user, factor] += lr * (err * qif - reg * puf)\n",
        "            qi[item, factor] += lr * (err * puf - reg * qif)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "GfJvaolmFPfT"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\DUY\\AppData\\Local\\Temp\\ipykernel_2156\\284637194.py:1: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
            "  @jit(cache=True)\n"
          ]
        }
      ],
      "source": [
        "@jit(cache=True)\n",
        "def compute_val_metrics(X_val, bu, bi, pu, qi, global_mean, n_factors):\n",
        "    residuals = []\n",
        "\n",
        "    for i in range(X_val.shape[0]):\n",
        "        user, item, rating = int(X_val[i, 0]), int(X_val[i, 1]), X_val[i, 2]\n",
        "\n",
        "        pred = global_mean\n",
        "\n",
        "        if user > -1:\n",
        "            pred += bu[user]\n",
        "\n",
        "        if item > -1:\n",
        "            pred += bi[item]\n",
        "\n",
        "        if (user > -1) and (item > -1):\n",
        "            for factor in range(n_factors):\n",
        "                pred += pu[user, factor] * qi[item, factor]\n",
        "\n",
        "        residuals.append(rating - pred)\n",
        "\n",
        "    residuals = np.array(residuals)\n",
        "    loss = np.square(residuals).mean()\n",
        "    rmse = np.sqrt(loss)\n",
        "    mae = np.absolute(residuals).mean()\n",
        "\n",
        "    return loss, rmse, mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "NGWhEWCSFPfU"
      },
      "outputs": [],
      "source": [
        "class bcolors:\n",
        "    GREEN = \"\\033[92m\"\n",
        "    YELLOW = \"\\033[93m\"\n",
        "    RED = \"\\033[91m\"\n",
        "    ENDC = \"\\033[0m\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "EqbTxx8OFPfU"
      },
      "outputs": [],
      "source": [
        "class SVD:\n",
        "    def __init__(\n",
        "        self,\n",
        "        lr=0.005,\n",
        "        reg=0.02,\n",
        "        n_epochs=20,\n",
        "        n_factors=100,\n",
        "        early_stopping=True,\n",
        "        min_delta=0.001,\n",
        "        min_rating=1,\n",
        "        max_rating=5,\n",
        "        parallel=True\n",
        "    ):\n",
        "\n",
        "        self.lr = lr\n",
        "        self.reg = reg\n",
        "        self.n_epochs = n_epochs\n",
        "        self.n_factors = n_factors\n",
        "        self.early_stopping = early_stopping\n",
        "        self.shuffle = shuffle\n",
        "        self.min_delta = min_delta\n",
        "        self.min_rating = min_rating\n",
        "        self.max_rating = max_rating\n",
        "        self.parallel = parallel\n",
        "        self.log = []\n",
        "\n",
        "    def fit(self, X, X_val=None):\n",
        "        # Preprocess the training data\n",
        "        X = self.preprocess_data(X)\n",
        "\n",
        "        # Check if validation data is provided\n",
        "        if X_val is not None:\n",
        "            # Preprocess the validation data\n",
        "            X_val = self.preprocess_data(X_val, train=False)\n",
        "            # Initialize metrics for evaluation\n",
        "            self.init_metrics()\n",
        "\n",
        "        # Calculate the global mean of the rating feature\n",
        "        self.global_mean_ = np.mean(X[:, 2])\n",
        "\n",
        "        # Run the Stochastic Gradient Descent (SGD) algorithm\n",
        "        self.run_sgd(X, X_val)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def preprocess_data(self, X, train=True):\n",
        "        # Copy the data to avoid modifying the original DataFrame\n",
        "        X = X.copy()\n",
        "\n",
        "        # Mappings are only needed during training\n",
        "        if train:\n",
        "            # Create unique mappings for user and item IDs (if training)\n",
        "            user_ids = X[\"u_id\"].unique().tolist()\n",
        "            item_ids = X[\"i_id\"].unique().tolist()\n",
        "\n",
        "            n_users = len(user_ids)\n",
        "            n_items = len(item_ids)\n",
        "\n",
        "            user_idx = range(n_users)\n",
        "            item_idx = range(n_items)\n",
        "\n",
        "            self.user_mapping_ = dict(zip(user_ids, user_idx))\n",
        "            self.item_mapping_ = dict(zip(item_ids, item_idx))\n",
        "\n",
        "        # Replace user and item IDs with their corresponding indices in the mappings\n",
        "        X[\"u_id\"] = X[\"u_id\"].map(self.user_mapping_)\n",
        "        X[\"i_id\"] = X[\"i_id\"].map(self.item_mapping_)\n",
        "\n",
        "        # Tag unseen users/items in validation data with -1 (for handling unknown entries)\n",
        "        X.fillna(-1, inplace=True)\n",
        "\n",
        "        X[\"u_id\"] = X[\"u_id\"].astype(np.int32)\n",
        "        X[\"i_id\"] = X[\"i_id\"].astype(np.int32)\n",
        "\n",
        "        return X[[\"u_id\", \"i_id\", \"rating\"]].values\n",
        "\n",
        "    def init_metrics(self):\n",
        "        # Initialize empty metrics array with zeros\n",
        "        metrics = np.zeros((self.n_epochs, 3), dtype=float)\n",
        "\n",
        "        # Create a pandas DataFrame from the metrics array\n",
        "        self.metrics_ = pd.DataFrame(metrics, columns=[\"Loss\", \"RMSE\", \"MAE\"])\n",
        "\n",
        "    def run_sgd(self, X, X_val):\n",
        "        # Get number of unique users\n",
        "        n_users = len(np.unique(X[:, 0]))\n",
        "\n",
        "        # Get number of unique items\n",
        "        n_items = len(np.unique(X[:, 1]))\n",
        "\n",
        "        # Initialize model parameters\n",
        "        bu, bi, pu, qi = initialization(n_users, n_items, self.n_factors)\n",
        "\n",
        "        # Run SGD for specified number of epochs\n",
        "        for epoch_ix in range(self.n_epochs):\n",
        "            start = self.on_epoch_begin(epoch_ix)\n",
        "\n",
        "            if not self.parallel:\n",
        "              X = shuffle(X)\n",
        "\n",
        "              # Update model parameters using run_epoch function\n",
        "              run_epoch_cpu(\n",
        "                X, bu, bi, pu, qi, self.global_mean_, self.n_factors, self.lr, self.reg\n",
        "              )\n",
        "            else:\n",
        "              block_size = 32\n",
        "              grid_size = math.ceil(X.shape[0] / block_size)\n",
        "\n",
        "              # Update model parameters using run_epoch function\n",
        "              run_epoch_gpu[grid_size, block_size](\n",
        "                  X, bu, bi, pu, qi, self.global_mean_, self.n_factors, self.lr, self.reg\n",
        "              )\n",
        "\n",
        "            if X_val is not None:\n",
        "                # Compute validation metrics if validation data provided\n",
        "                self.metrics_.loc[epoch_ix, :] = compute_val_metrics(\n",
        "                    X_val, bu, bi, pu, qi, self.global_mean_, self.n_factors\n",
        "                )\n",
        "                self.on_epoch_end(\n",
        "                    start,\n",
        "                    self.metrics_.loc[epoch_ix, \"Loss\"],\n",
        "                    self.metrics_.loc[epoch_ix, \"RMSE\"],\n",
        "                    self.metrics_.loc[epoch_ix, \"MAE\"],\n",
        "                )\n",
        "\n",
        "                self.log.append(self.metrics_.loc[epoch_ix, \"RMSE\"])\n",
        "\n",
        "                if self.early_stopping:\n",
        "                    val_rmse = self.metrics_[\"RMSE\"].tolist()\n",
        "                    if self.check_early_stopping(val_rmse, epoch_ix, self.min_delta):\n",
        "                        break\n",
        "\n",
        "            else:\n",
        "                self.on_epoch_end(start)\n",
        "\n",
        "        # Update internal model parameters with learned values\n",
        "        self.bu_ = bu\n",
        "        self.bi_ = bi\n",
        "        self.pu_ = pu\n",
        "        self.qi_ = qi\n",
        "\n",
        "    def predict(self, X, clip=True):\n",
        "        # Generate predictions for each user-item pair in X\n",
        "        return [\n",
        "            self.predict_pair(u_id, i_id, clip)\n",
        "            for u_id, i_id in zip(X[\"u_id\"], X[\"i_id\"])\n",
        "        ]\n",
        "\n",
        "    def predict_with_uid(self, X, u_id, clip=True):\n",
        "        # Generate predictions for each user-item pair in X\n",
        "        return [\n",
        "            [self.predict_pair(u_id, i_id, clip), i_id]\n",
        "            for i_id in X[\"i_id\"].unique()\n",
        "        ]\n",
        "\n",
        "    def predict_pair(self, u_id, i_id, clip=True):\n",
        "        # Initialize flags indicating if user and item are known\n",
        "        user_known, item_known = False, False\n",
        "\n",
        "        # Start prediction with global mean rating\n",
        "        pred = self.global_mean_\n",
        "\n",
        "        # Check if user ID exists in user mapping\n",
        "        if u_id in self.user_mapping_:\n",
        "            user_known = True\n",
        "            # Get user index\n",
        "            u_ix = self.user_mapping_[u_id]\n",
        "            # Add user bias\n",
        "            pred += self.bu_[u_ix]\n",
        "\n",
        "        # Check if item ID exists in item mapping\n",
        "        if i_id in self.item_mapping_:\n",
        "            item_known = True\n",
        "            # Get user index\n",
        "            i_ix = self.item_mapping_[i_id]\n",
        "            # Add user bias\n",
        "            pred += self.bi_[i_ix]\n",
        "\n",
        "        # If both user and item are known, add user-item interaction component\n",
        "        if user_known and item_known:\n",
        "            pred += np.dot(self.pu_[u_ix], self.qi_[i_ix])\n",
        "\n",
        "        # Clip the predicted rating to the defined range (if clip is True)\n",
        "        if clip:\n",
        "            pred = self.max_rating if pred > self.max_rating else pred\n",
        "            pred = self.min_rating if pred < self.min_rating else pred\n",
        "\n",
        "        return pred\n",
        "\n",
        "    def check_early_stopping(self, val_rmse, epoch_idx, min_delta):\n",
        "        if epoch_idx > 0:\n",
        "            # Check if validation RMSE has worsened by more than min_delta\n",
        "            if val_rmse[epoch_idx] + min_delta > val_rmse[epoch_idx - 1]:\n",
        "                # Update metrics DataFrame up to the current epoch\n",
        "                self.metrics_ = self.metrics_.loc[: (epoch_idx + 1), :]\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def on_epoch_begin(self, epoch_ix):\n",
        "        start = time.time()\n",
        "        end = \"  | \" if epoch_ix < 9 else \" | \"\n",
        "        print(\n",
        "            f\"{bcolors.YELLOW}[EPOCH]:{bcolors.ENDC} {epoch_ix + 1}/{self.n_epochs}\",\n",
        "            end=end,\n",
        "        )\n",
        "\n",
        "        return start\n",
        "\n",
        "    def on_epoch_end(self, start, val_loss=None, val_rmse=None, val_mae=None):\n",
        "        end = time.time()\n",
        "\n",
        "        if val_loss is not None:\n",
        "            print(f\"[VAL_LOSS]: {val_loss:.2f}\", end=\" - \")\n",
        "            print(f\"[VAL_RMSE]: {val_rmse:.2f}\", end=\" - \")\n",
        "            print(f\"[VAL_MAE]: {val_mae:.2f}\", end=\" | \")\n",
        "\n",
        "        print(f\"{bcolors.GREEN}[TIME]:{bcolors.ENDC} {end - start:.2f} s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0kC1w2dFPfV",
        "outputId": "f76f5f8e-0ec4-40db-9699-a7ad3936219a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[93m[EPOCH]:\u001b[0m 1/50  | "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python311\\Lib\\site-packages\\numba\\cuda\\cudadrv\\devicearray.py:886: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[VAL_LOSS]: 0.85 - [VAL_RMSE]: 0.92 - [VAL_MAE]: 0.71 | \u001b[92m[TIME]:\u001b[0m 3.64 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 2/50  | [VAL_LOSS]: 0.81 - [VAL_RMSE]: 0.90 - [VAL_MAE]: 0.69 | \u001b[92m[TIME]:\u001b[0m 3.46 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 3/50  | [VAL_LOSS]: 0.79 - [VAL_RMSE]: 0.89 - [VAL_MAE]: 0.68 | \u001b[92m[TIME]:\u001b[0m 3.47 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 4/50  | [VAL_LOSS]: 0.78 - [VAL_RMSE]: 0.88 - [VAL_MAE]: 0.67 | \u001b[92m[TIME]:\u001b[0m 3.48 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 5/50  | [VAL_LOSS]: 0.77 - [VAL_RMSE]: 0.88 - [VAL_MAE]: 0.67 | \u001b[92m[TIME]:\u001b[0m 3.45 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 6/50  | [VAL_LOSS]: 0.76 - [VAL_RMSE]: 0.87 - [VAL_MAE]: 0.67 | \u001b[92m[TIME]:\u001b[0m 3.50 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 7/50  | [VAL_LOSS]: 0.76 - [VAL_RMSE]: 0.87 - [VAL_MAE]: 0.66 | \u001b[92m[TIME]:\u001b[0m 3.48 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 8/50  | [VAL_LOSS]: 0.75 - [VAL_RMSE]: 0.87 - [VAL_MAE]: 0.66 | \u001b[92m[TIME]:\u001b[0m 3.50 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 9/50  | [VAL_LOSS]: 0.75 - [VAL_RMSE]: 0.87 - [VAL_MAE]: 0.66 | \u001b[92m[TIME]:\u001b[0m 3.49 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 10/50 | [VAL_LOSS]: 0.75 - [VAL_RMSE]: 0.86 - [VAL_MAE]: 0.66 | \u001b[92m[TIME]:\u001b[0m 3.54 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 11/50 | [VAL_LOSS]: 0.74 - [VAL_RMSE]: 0.86 - [VAL_MAE]: 0.66 | \u001b[92m[TIME]:\u001b[0m 3.51 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 12/50 | [VAL_LOSS]: 0.74 - [VAL_RMSE]: 0.86 - [VAL_MAE]: 0.66 | \u001b[92m[TIME]:\u001b[0m 3.48 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 13/50 | [VAL_LOSS]: 0.74 - [VAL_RMSE]: 0.86 - [VAL_MAE]: 0.65 | \u001b[92m[TIME]:\u001b[0m 3.49 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 14/50 | [VAL_LOSS]: 0.73 - [VAL_RMSE]: 0.85 - [VAL_MAE]: 0.65 | \u001b[92m[TIME]:\u001b[0m 3.47 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 15/50 | [VAL_LOSS]: 0.72 - [VAL_RMSE]: 0.85 - [VAL_MAE]: 0.65 | \u001b[92m[TIME]:\u001b[0m 3.49 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 16/50 | [VAL_LOSS]: 0.72 - [VAL_RMSE]: 0.85 - [VAL_MAE]: 0.64 | \u001b[92m[TIME]:\u001b[0m 3.51 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 17/50 | [VAL_LOSS]: 0.71 - [VAL_RMSE]: 0.84 - [VAL_MAE]: 0.64 | \u001b[92m[TIME]:\u001b[0m 3.47 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 18/50 | [VAL_LOSS]: 0.71 - [VAL_RMSE]: 0.84 - [VAL_MAE]: 0.64 | \u001b[92m[TIME]:\u001b[0m 3.43 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 19/50 | [VAL_LOSS]: 0.70 - [VAL_RMSE]: 0.84 - [VAL_MAE]: 0.64 | \u001b[92m[TIME]:\u001b[0m 3.47 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 20/50 | [VAL_LOSS]: 0.70 - [VAL_RMSE]: 0.83 - [VAL_MAE]: 0.63 | \u001b[92m[TIME]:\u001b[0m 3.48 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 21/50 | [VAL_LOSS]: 0.69 - [VAL_RMSE]: 0.83 - [VAL_MAE]: 0.63 | \u001b[92m[TIME]:\u001b[0m 3.47 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 22/50 | [VAL_LOSS]: 0.69 - [VAL_RMSE]: 0.83 - [VAL_MAE]: 0.63 | \u001b[92m[TIME]:\u001b[0m 3.49 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 23/50 | [VAL_LOSS]: 0.68 - [VAL_RMSE]: 0.83 - [VAL_MAE]: 0.63 | \u001b[92m[TIME]:\u001b[0m 3.48 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 24/50 | [VAL_LOSS]: 0.68 - [VAL_RMSE]: 0.82 - [VAL_MAE]: 0.62 | \u001b[92m[TIME]:\u001b[0m 3.48 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 25/50 | [VAL_LOSS]: 0.67 - [VAL_RMSE]: 0.82 - [VAL_MAE]: 0.62 | \u001b[92m[TIME]:\u001b[0m 3.48 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 26/50 | [VAL_LOSS]: 0.67 - [VAL_RMSE]: 0.82 - [VAL_MAE]: 0.62 | \u001b[92m[TIME]:\u001b[0m 3.54 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 27/50 | [VAL_LOSS]: 0.66 - [VAL_RMSE]: 0.82 - [VAL_MAE]: 0.62 | \u001b[92m[TIME]:\u001b[0m 3.48 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 28/50 | [VAL_LOSS]: 0.66 - [VAL_RMSE]: 0.81 - [VAL_MAE]: 0.62 | \u001b[92m[TIME]:\u001b[0m 3.52 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 29/50 | [VAL_LOSS]: 0.66 - [VAL_RMSE]: 0.81 - [VAL_MAE]: 0.61 | \u001b[92m[TIME]:\u001b[0m 3.51 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 30/50 | [VAL_LOSS]: 0.65 - [VAL_RMSE]: 0.81 - [VAL_MAE]: 0.61 | \u001b[92m[TIME]:\u001b[0m 3.52 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 31/50 | [VAL_LOSS]: 0.65 - [VAL_RMSE]: 0.81 - [VAL_MAE]: 0.61 | \u001b[92m[TIME]:\u001b[0m 3.49 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 32/50 | [VAL_LOSS]: 0.65 - [VAL_RMSE]: 0.80 - [VAL_MAE]: 0.61 | \u001b[92m[TIME]:\u001b[0m 3.47 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 33/50 | [VAL_LOSS]: 0.64 - [VAL_RMSE]: 0.80 - [VAL_MAE]: 0.61 | \u001b[92m[TIME]:\u001b[0m 3.49 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 34/50 | [VAL_LOSS]: 0.64 - [VAL_RMSE]: 0.80 - [VAL_MAE]: 0.61 | \u001b[92m[TIME]:\u001b[0m 3.49 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 35/50 | [VAL_LOSS]: 0.64 - [VAL_RMSE]: 0.80 - [VAL_MAE]: 0.60 | \u001b[92m[TIME]:\u001b[0m 3.48 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 36/50 | [VAL_LOSS]: 0.64 - [VAL_RMSE]: 0.80 - [VAL_MAE]: 0.60 | \u001b[92m[TIME]:\u001b[0m 3.47 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 37/50 | [VAL_LOSS]: 0.63 - [VAL_RMSE]: 0.80 - [VAL_MAE]: 0.60 | \u001b[92m[TIME]:\u001b[0m 3.51 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 38/50 | [VAL_LOSS]: 0.63 - [VAL_RMSE]: 0.79 - [VAL_MAE]: 0.60 | \u001b[92m[TIME]:\u001b[0m 3.49 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 39/50 | [VAL_LOSS]: 0.63 - [VAL_RMSE]: 0.79 - [VAL_MAE]: 0.60 | \u001b[92m[TIME]:\u001b[0m 3.50 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 40/50 | [VAL_LOSS]: 0.63 - [VAL_RMSE]: 0.79 - [VAL_MAE]: 0.60 | \u001b[92m[TIME]:\u001b[0m 3.50 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 41/50 | [VAL_LOSS]: 0.63 - [VAL_RMSE]: 0.79 - [VAL_MAE]: 0.60 | \u001b[92m[TIME]:\u001b[0m 3.53 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 42/50 | [VAL_LOSS]: 0.62 - [VAL_RMSE]: 0.79 - [VAL_MAE]: 0.60 | \u001b[92m[TIME]:\u001b[0m 3.50 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 43/50 | [VAL_LOSS]: 0.62 - [VAL_RMSE]: 0.79 - [VAL_MAE]: 0.60 | \u001b[92m[TIME]:\u001b[0m 3.50 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 44/50 | [VAL_LOSS]: 0.62 - [VAL_RMSE]: 0.79 - [VAL_MAE]: 0.60 | \u001b[92m[TIME]:\u001b[0m 3.50 s\n",
            "\u001b[93m[EPOCH]:\u001b[0m 45/50 | [VAL_LOSS]: 0.62 - [VAL_RMSE]: 0.79 - [VAL_MAE]: 0.59 | \u001b[92m[TIME]:\u001b[0m 3.50 s\n",
            "\n",
            "\u001b[91m[PROCESSING TIME]:\u001b[0m 168.77 s\n"
          ]
        }
      ],
      "source": [
        "svd = SVD(\n",
        "    lr=0.001,\n",
        "    reg=0.005,\n",
        "    n_epochs=50,\n",
        "    n_factors=25,\n",
        "    early_stopping=True,\n",
        "    min_rating=1,\n",
        "    max_rating=5,\n",
        "    parallel=True\n",
        ")\n",
        "\n",
        "start = time.time()\n",
        "svd.fit(X=train, X_val=val)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"\\n{bcolors.RED}[PROCESSING TIME]:{bcolors.ENDC} {end - start:.2f} s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "a_Y-7r9xFPfW"
      },
      "outputs": [],
      "source": [
        "pred = svd.predict(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvBhiAxQFPfX",
        "outputId": "14be6091-f877-4f24-de2f-3122e02d4020"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[91m[TEST RMSE]:\u001b[0m 0.79\n"
          ]
        }
      ],
      "source": [
        "rmse = mean_squared_error(test[\"rating\"], pred, squared = False)\n",
        "print(f\"\\n{bcolors.RED}[TEST RMSE]:{bcolors.ENDC} {rmse:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "cFqV4B7vKyjk",
        "outputId": "8824e816-f7f7-467d-cf1d-97f255462219"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create epoch values\n",
        "epochs = np.arange(1, len(svd.log) + 1)\n",
        "\n",
        "# Plot the data\n",
        "plt.plot(epochs, svd.log, color='r', label='RMSE')\n",
        "\n",
        "# Customize x and y labels\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "\n",
        "# Add a legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Recommend List Phim ra cho User vi Input l User ID tng ng:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CHON U_ID DE RECOMMEND (500 hoac 550)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "u_id = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        "recommend = svd.predict_with_uid(df, u_id)\n",
        "recommend = sorted(recommend, key=lambda row: -row[0])[:10]\n",
        "# ====================\n",
        "# Construct the path to the CSV file\n",
        "csv_path = os.path.join(dirname, \"movies.csv\")\n",
        "\n",
        "# Define the column names for the data\n",
        "names = [\"movie_id\", \"title\", \"gernes\"]\n",
        "\n",
        "# Read the CSV data into a Pandas DataFrame\n",
        "df_m = pd.read_csv(\n",
        "    csv_path,\n",
        "    names=names,\n",
        "    header=0,\n",
        "    sep=\",\",\n",
        "    encoding=\"latin-1\"\n",
        ")\n",
        "\n",
        "df_m = df_m[['movie_id','title']]\n",
        "i_dict = dict(df_m.values)\n",
        "for i in range(len(recommend)):\n",
        "    recommend[i][1] = i_dict[recommend[i][1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = df.loc[df['u_id']==u_id,:] # Lich s phim m User   nh gi\n",
        "history = history.sort_values(by=['rating'], ascending=False)[:10]\n",
        "\n",
        "best_history = [] # Lich s phim m User  nh gi cao nht (Gn vi 5 sao nht)\n",
        "for i in range(len(history)):\n",
        "    best_history.append([history.iloc[i]['rating'], i_dict[history.iloc[i]['i_id']]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[5.0, 'Beautiful Mind, A (2001)'],\n",
              " [5.0, 'Eternal Sunshine of the Spotless Mind (2004)'],\n",
              " [5.0, 'Little Miss Sunshine (2006)'],\n",
              " [5.0,\n",
              "  'Borat: Cultural Learnings of America for Make Benefit Glorious Nation of Kazakhstan (2006)'],\n",
              " [5.0, 'Star Wars: Episode I - The Phantom Menace (1999)'],\n",
              " [5.0, 'Star Wars: Episode IV - A New Hope (1977)'],\n",
              " [5.0, 'Ace Ventura: Pet Detective (1994)'],\n",
              " [5.0, 'True Lies (1994)'],\n",
              " [5.0, 'Aladdin (1992)'],\n",
              " [5.0, 'Silence of the Lambs, The (1991)']]"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Output ra Lich s phim m User  nh gi cao nht (Gn vi 5 sao nht)\n",
        "best_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[4.348941642277699, 'Band of Brothers (2001)'],\n",
              " [4.3259623640338445, 'North & South (2004)'],\n",
              " [4.312286757160266, 'Remember the Titans (2000)'],\n",
              " [4.306789964504656, 'I, Claudius (1976)'],\n",
              " [4.289979680153283, 'Braveheart (1995)'],\n",
              " [4.266477458165111, 'The Rescue (2021)'],\n",
              " [4.264089732917146, 'Sound of Music, The (1965)'],\n",
              " [4.260276595934408, 'Baseball (1994)'],\n",
              " [4.258796322675445, 'Human Condition II, The (Ningen no joken II) (1959)'],\n",
              " [4.258485014046715, 'Gladiator (1992)']]"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Output ra list phim  xut\n",
        "recommend"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## So snh Runtime vi vic dng Th vin Surprise:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "from surprise import SVD\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 42.9 s\n",
            "Wall time: 50.7 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "trainset = Dataset.load_from_df(train[['u_id', 'i_id', 'rating']],\n",
        "                               reader=reader).build_full_trainset()\n",
        "\n",
        "testset = Dataset.load_from_df(test[['u_id', 'i_id', 'rating']], reader=reader)\n",
        "testset = testset.construct_testset(testset.raw_ratings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing epoch 0\n",
            "Processing epoch 1\n",
            "Processing epoch 2\n",
            "Processing epoch 3\n",
            "Processing epoch 4\n",
            "Processing epoch 5\n",
            "Processing epoch 6\n",
            "Processing epoch 7\n",
            "Processing epoch 8\n",
            "Processing epoch 9\n",
            "Processing epoch 10\n",
            "Processing epoch 11\n",
            "Processing epoch 12\n",
            "Processing epoch 13\n",
            "Processing epoch 14\n",
            "Processing epoch 15\n",
            "Processing epoch 16\n",
            "Processing epoch 17\n",
            "Processing epoch 18\n",
            "Processing epoch 19\n",
            "Processing epoch 20\n",
            "Processing epoch 21\n",
            "Processing epoch 22\n",
            "Processing epoch 23\n",
            "Processing epoch 24\n",
            "Processing epoch 25\n",
            "Processing epoch 26\n",
            "Processing epoch 27\n",
            "Processing epoch 28\n",
            "Processing epoch 29\n",
            "Processing epoch 30\n",
            "Processing epoch 31\n",
            "Processing epoch 32\n",
            "Processing epoch 33\n",
            "Processing epoch 34\n",
            "Processing epoch 35\n",
            "Processing epoch 36\n",
            "Processing epoch 37\n",
            "Processing epoch 38\n",
            "Processing epoch 39\n",
            "Processing epoch 40\n",
            "Processing epoch 41\n",
            "Processing epoch 42\n",
            "Processing epoch 43\n",
            "Processing epoch 44\n",
            "Processing epoch 45\n",
            "Processing epoch 46\n",
            "Processing epoch 47\n",
            "Processing epoch 48\n",
            "Processing epoch 49\n",
            "\n",
            "\u001b[91m[PROCESSING TIME]:\u001b[0m 955.58 s\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "svd = SVD(lr_all=0.001, reg_all=0.005, n_epochs=50, n_factors=100, verbose=True)\n",
        "svd.fit(trainset)\n",
        "end = time.time()\n",
        "print(f\"\\n{bcolors.RED}[PROCESSING TIME]:{bcolors.ENDC} {end - start:.2f} s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[91m[TEST RMSE]:\u001b[0m 0.79\n",
            "\n",
            "\u001b[91m[TEST MAE]:\u001b[0m 0.59\n",
            "\n",
            "CPU times: total: 26.3 s\n",
            "Wall time: 48.2 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "pred = svd.test(testset)\n",
        "y_true = [p.r_ui for p in pred]\n",
        "y_hat = [p.est for p in pred]\n",
        "\n",
        "rmse = mean_squared_error(y_true, y_hat, squared = False)\n",
        "mae = mean_absolute_error(y_true, y_hat)\n",
        "print(f\"\\n{bcolors.RED}[TEST RMSE]:{bcolors.ENDC} {rmse:.2f}\")\n",
        "print(f\"\\n{bcolors.RED}[TEST MAE]:{bcolors.ENDC} {mae:.2f}\")\n",
        "print()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
